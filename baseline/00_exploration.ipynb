{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ed64b3-bfcd-4201-adcf-660c7f1a9391",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this one to test the dgl \n",
    "import sys\n",
    "sys.path.append(\"/home/n/nguyenpk/CS6208/GNN_ERC/baseline/DialogueGCN-mianzhang\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb892f77-3401-4bd1-86fd-49c7da55c7ce",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4151712-4bab-46f7-95fa-916acd8664c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n/nguyenpk/miniconda3/envs/GNN_pytorch_DGL/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgcn\n",
    "\n",
    "log = dgcn.utils.get_logger()\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, tag_size, args):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.emotion_att = MaskedEmotionAtt(input_dim)\n",
    "        self.lin1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.drop = nn.Dropout(args.drop_rate)\n",
    "        self.lin2 = nn.Linear(hidden_size, tag_size)\n",
    "        if args.class_weight:\n",
    "            self.loss_weights = torch.tensor([1 / 0.086747, 1 / 0.144406, 1 / 0.227883,\n",
    "                                              1 / 0.160585, 1 / 0.127711, 1 / 0.252668]).to(args.device)\n",
    "            self.nll_loss = nn.NLLLoss(self.loss_weights)\n",
    "        else:\n",
    "            self.nll_loss = nn.NLLLoss()\n",
    "\n",
    "    def get_prob(self, h, text_len_tensor):\n",
    "        # h_hat = self.emotion_att(h, text_len_tensor)\n",
    "        # hidden = self.drop(F.relu(self.lin1(h_hat)))\n",
    "        hidden = self.drop(F.relu(self.lin1(h)))\n",
    "        scores = self.lin2(hidden)\n",
    "        log_prob = F.log_softmax(scores, dim=-1)\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    def forward(self, h, text_len_tensor):\n",
    "        log_prob = self.get_prob(h, text_len_tensor)\n",
    "        y_hat = torch.argmax(log_prob, dim=-1)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def get_loss(self, h, label_tensor, text_len_tensor):\n",
    "        log_prob = self.get_prob(h, text_len_tensor)\n",
    "        loss = self.nll_loss(log_prob, label_tensor)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class MaskedEmotionAtt(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(MaskedEmotionAtt, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def forward(self, h, text_len_tensor):\n",
    "        batch_size = text_len_tensor.size(0)\n",
    "        x = self.lin(h)  # [node_num, H]\n",
    "        ret = torch.zeros_like(h)\n",
    "        s = 0\n",
    "        for bi in range(batch_size):\n",
    "            cur_len = text_len_tensor[bi].item()\n",
    "            y = x[s: s + cur_len]\n",
    "            z = h[s: s + cur_len]\n",
    "            scores = torch.mm(z, y.t())  # [L, L]\n",
    "            probs = F.softmax(scores, dim=1)\n",
    "            out = z.unsqueeze(0) * probs.unsqueeze(-1)  # [1, L, H] x [L, L, 1] --> [L, L, H]\n",
    "            out = torch.sum(out, dim=1)  # [L, H]\n",
    "            ret[s: s + cur_len, :] = out\n",
    "            s += cur_len\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61dd48-6556-42c8-912e-9b79696ad053",
   "metadata": {},
   "source": [
    "### EdgeAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b290de07-5353-4a16-b0c7-3c622c8ce937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgcn\n",
    "\n",
    "log = dgcn.utils.get_logger()\n",
    "\n",
    "\n",
    "class EdgeAtt(nn.Module):\n",
    "\n",
    "    def __init__(self, g_dim, args):\n",
    "        super(EdgeAtt, self).__init__()\n",
    "        self.device = args.device\n",
    "        self.wp = args.wp\n",
    "        self.wf = args.wf\n",
    "\n",
    "        self.weight = nn.Parameter(torch.zeros((g_dim, g_dim)).float(), requires_grad=True)\n",
    "        var = 2. / (self.weight.size(0) + self.weight.size(1))\n",
    "        self.weight.data.normal_(0, var)\n",
    "\n",
    "    def forward(self, node_features, text_len_tensor, edge_ind):\n",
    "        batch_size, mx_len = node_features.size(0), node_features.size(1)\n",
    "        alphas = []\n",
    "\n",
    "        weight = self.weight.unsqueeze(0).unsqueeze(0)\n",
    "        att_matrix = torch.matmul(weight, node_features.unsqueeze(-1)).squeeze(-1)  # [B, L, D_g]\n",
    "        for i in range(batch_size):\n",
    "            cur_len = text_len_tensor[i].item()\n",
    "            alpha = torch.zeros((mx_len, 110)).to(self.device)\n",
    "            for j in range(cur_len):\n",
    "                s = j - self.wp if j - self.wp >= 0 else 0\n",
    "                e = j + self.wf if j + self.wf <= cur_len - 1 else cur_len - 1\n",
    "                tmp = att_matrix[i, s: e + 1, :]  # [L', D_g]\n",
    "                feat = node_features[i, j]  # [D_g]\n",
    "                score = torch.matmul(tmp, feat)\n",
    "                probs = F.softmax(score)  # [L']\n",
    "                alpha[j, s: e + 1] = probs\n",
    "            alphas.append(alpha)\n",
    "\n",
    "        return alphas\n",
    "\n",
    "# class EdgeAtt(nn.Module):\n",
    "#\n",
    "#     def __init__(self, g_dim, args):\n",
    "#         super(EdgeAtt, self).__init__()\n",
    "#         self.device = args.device\n",
    "#         self.wp = args.wp\n",
    "#         self.wf = args.wf\n",
    "#         self.lin = nn.Linear(g_dim, 110)\n",
    "#\n",
    "#     def forward(self, node_features, text_len_tensor, edge_ind):\n",
    "#         h = self.lin(node_features)  # [B, L, mx]\n",
    "#         alphas = F.softmax(h, dim=-1)\n",
    "#         # alphas = torch.ones((node_features.size(0), node_features.size(1), 110))\n",
    "#         return alphas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9a0fe-7272-4faa-84a2-e688d5407642",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc48af5-7a1f-4464-b745-01420c073264",
   "metadata": {},
   "outputs": [],
   "source": [
    "### original"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac8286f9-e850-4b1c-8d3c-113f0bd47739",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "# from dgl.nn.pytorch import RelGraphConv as RGCNConv\n",
    "# from dgl.nn.pytorch import GraphConv\n",
    "from torch_geometric.nn import GraphConv\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "def uniform(size, tensor):\n",
    "    bound = 1.0 / math.sqrt(size)\n",
    "    if tensor is not None:\n",
    "        tensor.data.uniform_(-bound, bound)\n",
    "\n",
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, num_bases, dropout):\n",
    "        super(RGCN, self).__init__()\n",
    "\n",
    "        self.entity_embedding = nn.Embedding(num_entities, 100)\n",
    "        self.relation_embedding = nn.Parameter(torch.Tensor(num_relations, 100))\n",
    "\n",
    "        nn.init.xavier_uniform_(self.relation_embedding, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        self.conv1 = RGCNConv(100, 100, num_relations * 2, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(100, 100, num_relations * 2, num_bases=num_bases)\n",
    "        self.dropout_ratio = dropout\n",
    "\n",
    "    def forward(self, entity, edge_index, edge_type, edge_norm):\n",
    "        x = self.entity_embedding(entity)\n",
    "        x = self.conv1(x, edge_index, edge_type, edge_norm)\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_type, edge_norm))\n",
    "        x = F.dropout(x, p = self.dropout_ratio, training = self.training)\n",
    "        x = self.conv2(x, edge_index, edge_type, edge_norm)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def distmult(self, embedding, triplets):\n",
    "        s = embedding[triplets[:,0]]\n",
    "        r = self.relation_embedding[triplets[:,1]]\n",
    "        o = embedding[triplets[:,2]]\n",
    "        score = torch.sum(s * r * o, dim=1)\n",
    "        \n",
    "        return score\n",
    "\n",
    "    def score_loss(self, embedding, triplets, target):\n",
    "        score = self.distmult(embedding, triplets)\n",
    "\n",
    "        return score, F.binary_cross_entropy_with_logits(score, target)\n",
    "\n",
    "    def reg_loss(self, embedding):\n",
    "        return torch.mean(embedding.pow(2)) + torch.mean(self.relation_embedding.pow(2))\n",
    "\n",
    "class RGCNConv(MessagePassing):\n",
    "    r\"\"\"The relational graph convolutional operator from the `\"Modeling\n",
    "    Relational Data with Graph Convolutional Networks\"\n",
    "    <https://arxiv.org/abs/1703.06103>`_ paper\n",
    "    .. math::\n",
    "        \\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_{\\textrm{root}} \\cdot\n",
    "        \\mathbf{x}_i + \\sum_{r \\in \\mathcal{R}} \\sum_{j \\in \\mathcal{N}_r(i)}\n",
    "        \\frac{1}{|\\mathcal{N}_r(i)|} \\mathbf{\\Theta}_r \\cdot \\mathbf{x}_j,\n",
    "    where :math:`\\mathcal{R}` denotes the set of relations, *i.e.* edge types.\n",
    "    Edge type needs to be a one-dimensional :obj:`torch.long` tensor which\n",
    "    stores a relation identifier\n",
    "    :math:`\\in \\{ 0, \\ldots, |\\mathcal{R}| - 1\\}` for each edge.\n",
    "    Args:\n",
    "        in_channels (int): Size of each input sample.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        num_relations (int): Number of relations.\n",
    "        num_bases (int): Number of bases used for basis-decomposition.\n",
    "        root_weight (bool, optional): If set to :obj:`False`, the layer will\n",
    "            not add transformed root node features to the output.\n",
    "            (default: :obj:`True`)\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_relations, num_bases,\n",
    "                 root_weight=True, bias=True, **kwargs):\n",
    "        super(RGCNConv, self).__init__(aggr='mean', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_relations = num_relations\n",
    "        self.num_bases = num_bases\n",
    "\n",
    "        self.basis = nn.Parameter(torch.Tensor(num_bases, in_channels, out_channels))\n",
    "        self.att = nn.Parameter(torch.Tensor(num_relations, num_bases))\n",
    "\n",
    "        if root_weight:\n",
    "            self.root = nn.Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        size = self.num_bases * self.in_channels\n",
    "        uniform(size, self.basis)\n",
    "        uniform(size, self.att)\n",
    "        uniform(size, self.root)\n",
    "        uniform(size, self.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type, edge_norm=None, size=None):\n",
    "        \"\"\"\"\"\"\n",
    "        return self.propagate(edge_index, size=size, x=x, edge_type=edge_type,\n",
    "                              edge_norm=edge_norm)\n",
    "\n",
    "\n",
    "    def message(self, x_j, edge_index_j, edge_type, edge_norm):\n",
    "        w = torch.matmul(self.att, self.basis.view(self.num_bases, -1))\n",
    "\n",
    "        # If no node features are given, we implement a simple embedding\n",
    "        # loopkup based on the target node index and its edge type.\n",
    "        if x_j is None:\n",
    "            w = w.view(-1, self.out_channels)\n",
    "            index = edge_type * self.in_channels + edge_index_j\n",
    "            out = torch.index_select(w, 0, index)\n",
    "        else:\n",
    "            w = w.view(self.num_relations, self.in_channels, self.out_channels)\n",
    "            w = torch.index_select(w, 0, edge_type)\n",
    "            out = torch.bmm(x_j.unsqueeze(1), w).squeeze(-2)\n",
    "\n",
    "        return out if edge_norm is None else out * edge_norm.view(-1, 1)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        if self.root is not None:\n",
    "            if x is None:\n",
    "                out = aggr_out + self.root\n",
    "            else:\n",
    "                out = aggr_out + torch.matmul(x, self.root)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, num_relations={})'.format(\n",
    "            self.__class__.__name__, self.in_channels, self.out_channels,\n",
    "            self.num_relations)\n",
    "\n",
    "class GCN(nn.Module):\n",
    "\n",
    "    def __init__(self, g_dim, h1_dim, h2_dim, args):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_relations = 2 * args.n_speakers ** 2\n",
    "        self.conv1 = RGCNConv(g_dim, h1_dim, self.num_relations, num_bases=30)\n",
    "        self.conv2 = GraphConv(h1_dim, h2_dim)\n",
    "\n",
    "    def forward(self, node_features, edge_index, edge_norm, edge_type):\n",
    "        x = self.conv1(node_features, edge_index, edge_type, edge_norm=edge_norm)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fe76ae3-c78e-4042-bad9-a690a46c98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dgl.nn.pytorch import RelGraphConv as RGCNConv\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "import dgcn\n",
    "log = dgcn.utils.get_logger()\n",
    "\n",
    "class GCN(nn.Module):\n",
    "\n",
    "    def __init__(self, g_dim, h1_dim, h2_dim, args):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_relations = 2 * args.n_speakers ** 2\n",
    "        self.conv1 = RGCNConv(g_dim, h1_dim, self.num_relations, num_bases=30)\n",
    "        # self.conv1 = myRGCNConv(g_dim, h1_dim, self.num_relations, num_bases=30)\n",
    "        self.conv2 = GraphConv(h1_dim, h2_dim)\n",
    "\n",
    "    def forward(self, node_features, edge_index, edge_norm, edge_type):\n",
    "\n",
    "        # x = self.conv1(node_features, edge_index, edge_type)\n",
    "        # x = self.conv2(x, edge_index, edge_weight=edge_norm)\n",
    "\n",
    "        x = self.conv1(node_features, edge_index, edge_type, edge_norm=edge_norm)\n",
    "        # log.info(\"x.shape = {}, {}\".format(x.shape, edge_norm.view(-1, 1).shape) )\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8497d-63b7-44c1-8765-505cbd0700d7",
   "metadata": {},
   "source": [
    "### SeqContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1bfb11b-2079-4a9e-a126-b1aa4e21f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class SeqContext(nn.Module):\n",
    "\n",
    "    def __init__(self, u_dim, g_dim, args):\n",
    "        super(SeqContext, self).__init__()\n",
    "        self.input_size = u_dim\n",
    "        self.hidden_dim = g_dim\n",
    "        if args.rnn == \"lstm\":\n",
    "            self.rnn = nn.LSTM(self.input_size, self.hidden_dim // 2, dropout=args.drop_rate,\n",
    "                               bidirectional=True, num_layers=2, batch_first=True)\n",
    "        elif args.rnn == \"gru\":\n",
    "            self.rnn = nn.GRU(self.input_size, self.hidden_dim // 2, dropout=args.drop_rate,\n",
    "                              bidirectional=True, num_layers=2, batch_first=True)\n",
    "\n",
    "    def forward(self, text_len_tensor, text_tensor):\n",
    "        packed = pack_padded_sequence(\n",
    "            text_tensor,\n",
    "            text_len_tensor.cpu(),\n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        print(len(self.rnn(packed, None)))\n",
    "        # rnn_out, (_, _) = self.rnn(packed, None)\n",
    "        rnn_out,  _ = self.rnn(packed, None)\n",
    "        rnn_out, _ = pad_packed_sequence(rnn_out, batch_first=True)\n",
    "\n",
    "        return rnn_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063e712-b4d4-4fcc-bf11-46efeabf4956",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "934d2023-aa8b-4111-b779-263dcb14fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import dgcn\n",
    "\n",
    "log = dgcn.utils.get_logger()\n",
    "\n",
    "\n",
    "def batch_graphify(features, lengths, speaker_tensor, wp, wf, edge_type_to_idx, att_model, device):\n",
    "    node_features, edge_index, edge_norm, edge_type = [], [], [], []\n",
    "    batch_size = features.size(0)\n",
    "    length_sum = 0\n",
    "    edge_ind = []\n",
    "    edge_index_lengths = []\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        edge_ind.append(edge_perms(lengths[j].cpu().item(), wp, wf))\n",
    "\n",
    "    edge_weights = att_model(features, lengths, edge_ind)\n",
    "\n",
    "    for j in range(batch_size):\n",
    "        cur_len = lengths[j].item()\n",
    "        node_features.append(features[j, :cur_len, :])\n",
    "        perms = edge_perms(cur_len, wp, wf)\n",
    "        perms_rec = [(item[0] + length_sum, item[1] + length_sum) for item in perms]\n",
    "        length_sum += cur_len\n",
    "        edge_index_lengths.append(len(perms))\n",
    "\n",
    "        for item, item_rec in zip(perms, perms_rec):\n",
    "            edge_index.append(torch.tensor([item_rec[0], item_rec[1]]))\n",
    "            edge_norm.append(edge_weights[j][item[0], item[1]])\n",
    "            # edge_norm.append(edge_weights[j, item[0], item[1]])\n",
    "\n",
    "            speaker1 = speaker_tensor[j, item[0]].item()\n",
    "            speaker2 = speaker_tensor[j, item[1]].item()\n",
    "            if item[0] < item[1]:\n",
    "                c = '0'\n",
    "            else:\n",
    "                c = '1'\n",
    "            edge_type.append(edge_type_to_idx[str(speaker1) + str(speaker2) + c])\n",
    "\n",
    "    node_features = torch.cat(node_features, dim=0).to(device)  # [E, D_g]\n",
    "    edge_index = torch.stack(edge_index).t().contiguous().to(device)  # [2, E]\n",
    "    edge_norm = torch.stack(edge_norm).to(device)  # [E]\n",
    "    edge_type = torch.tensor(edge_type).long().to(device)  # [E]\n",
    "    edge_index_lengths = torch.tensor(edge_index_lengths).long().to(device)  # [B]\n",
    "\n",
    "    return node_features, edge_index, edge_norm, edge_type, edge_index_lengths\n",
    "\n",
    "\n",
    "def edge_perms(length, window_past, window_future):\n",
    "    \"\"\"\n",
    "    Method to construct the edges of a graph (a utterance) considering the past and future window.\n",
    "    return: list of tuples. tuple -> (vertice(int), neighbor(int))\n",
    "    \"\"\"\n",
    "\n",
    "    all_perms = set()\n",
    "    array = np.arange(length)\n",
    "    for j in range(length):\n",
    "        perms = set()\n",
    "\n",
    "        if window_past == -1 and window_future == -1:\n",
    "            eff_array = array\n",
    "        elif window_past == -1:  # use all past context\n",
    "            eff_array = array[:min(length, j + window_future + 1)]\n",
    "        elif window_future == -1:  # use all future context\n",
    "            eff_array = array[max(0, j - window_past):]\n",
    "        else:\n",
    "            eff_array = array[max(0, j - window_past):min(length, j + window_future + 1)]\n",
    "\n",
    "        for item in eff_array:\n",
    "            perms.add((j, item))\n",
    "        all_perms = all_perms.union(perms)\n",
    "    return list(all_perms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cbf2aa-6c70-4e14-88c9-df07b940a873",
   "metadata": {},
   "source": [
    "### DialogueGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "195fb2f5-686c-444c-b3d4-d04bbeb587d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# from .SeqContext import SeqContext\n",
    "# from .EdgeAtt import EdgeAtt\n",
    "# from .GCN import GCN\n",
    "# from .Classifier import Classifier\n",
    "# from .functions import batch_graphify\n",
    "import dgcn\n",
    "\n",
    "log = dgcn.utils.get_logger()\n",
    "\n",
    "\n",
    "class DialogueGCN(nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(DialogueGCN, self).__init__()\n",
    "        u_dim = 100\n",
    "        g_dim = 200\n",
    "        h1_dim = 100\n",
    "        h2_dim = 100\n",
    "        hc_dim = 100\n",
    "        tag_size = 6\n",
    "\n",
    "        self.wp = args.wp\n",
    "        self.wf = args.wf\n",
    "        self.device = args.device\n",
    "\n",
    "        self.rnn = SeqContext(u_dim, g_dim, args)\n",
    "        self.edge_att = EdgeAtt(g_dim, args)\n",
    "        self.gcn = GCN(g_dim, h1_dim, h2_dim, args)\n",
    "        self.clf = Classifier(g_dim + h2_dim, hc_dim, tag_size, args)\n",
    "\n",
    "        edge_type_to_idx = {}\n",
    "        for j in range(args.n_speakers):\n",
    "            for k in range(args.n_speakers):\n",
    "                edge_type_to_idx[str(j) + str(k) + '0'] = len(edge_type_to_idx)\n",
    "                edge_type_to_idx[str(j) + str(k) + '1'] = len(edge_type_to_idx)\n",
    "        self.edge_type_to_idx = edge_type_to_idx\n",
    "        log.debug(self.edge_type_to_idx)\n",
    "\n",
    "    def get_rep(self, data):\n",
    "        node_features = self.rnn(data[\"text_len_tensor\"], data[\"text_tensor\"]) # [batch_size, mx_len, D_g]\n",
    "        features, edge_index, edge_norm, edge_type, edge_index_lengths = batch_graphify(\n",
    "            node_features, data[\"text_len_tensor\"], data[\"speaker_tensor\"], self.wp, self.wf,\n",
    "            self.edge_type_to_idx, self.edge_att, self.device)\n",
    "\n",
    "        graph_out = self.gcn(features, edge_index, edge_norm, edge_type)\n",
    "\n",
    "        return graph_out, features\n",
    "\n",
    "    def forward(self, data):\n",
    "        graph_out, features = self.get_rep(data)\n",
    "        out = self.clf(torch.cat([features, graph_out], dim=-1), data[\"text_len_tensor\"])\n",
    "\n",
    "        return out\n",
    "\n",
    "    def get_loss(self, data):\n",
    "        graph_out, features = self.get_rep(data)\n",
    "        loss = self.clf.get_loss(torch.cat([features, graph_out], dim=-1),\n",
    "                                 data[\"label_tensor\"], data[\"text_len_tensor\"])\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e9405-9911-4baf-bce3-573fbb2a2307",
   "metadata": {},
   "source": [
    "## Read data and check training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac96c5ee-1506-48fd-ad8d-d83477965591",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import necessary lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f2dcdda-bb06-487c-83ab-bf1e1ef02f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_path = \"/home/n/nguyenpk/CS6208/GNN_ERC/baseline/DialogueGCN-mianzhang\"\n",
    "data_path = os.path.join(base_path, \"data/iemocap/ckpt/data.pkl\")\n",
    "batch_size = 32\n",
    "device  = \"cuda:0\"\n",
    "learning_rate = 0.0003\n",
    "max_grad_value = -1\n",
    "weight_decay = 1e-8\n",
    "optimizer = \"adam\"\n",
    "\n",
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "args = Namespace(batch_size=batch_size, \n",
    "                 device=device,\n",
    "                 learning_rate=learning_rate,\n",
    "                 max_grad_value=max_grad_value, \n",
    "                 weight_decay=weight_decay, \n",
    "                 optimizer=optimizer, \n",
    "                 from_begin=True,\n",
    "                 epochs=1,\n",
    "                 drop_rate=0.5,\n",
    "                 wp=10,\n",
    "                 wf=10,\n",
    "                 n_speakers=2,\n",
    "                 hidden_size=100,\n",
    "                 rnn='gru',\n",
    "                 class_weight=True,\n",
    "                 seed=24,\n",
    "                 \n",
    ")\n",
    "data = dgcn.utils.load_pkl(data_path)\n",
    "trainset = dgcn.Dataset(data[\"train\"], args.batch_size)\n",
    "devset = dgcn.Dataset(data[\"dev\"], args.batch_size)\n",
    "testset = dgcn.Dataset(data[\"test\"], args.batch_size)\n",
    "\n",
    "model_file = \"./save/model.pt\"\n",
    "model = DialogueGCN(args).to(device)\n",
    "opt = dgcn.Optim(learning_rate, max_grad_value, weight_decay)\n",
    "opt.set_parameters(model.parameters(), optimizer)\n",
    "\n",
    "# coach = dgcn.Coach(trainset, devset, testset, model, opt, args)\n",
    "# ret = coach.train()\n",
    "\n",
    "#     # Save.\n",
    "#     checkpoint = {\n",
    "#         \"best_dev_f1\": ret[0],\n",
    "#         \"best_epoch\": ret[1],\n",
    "#         \"best_state\": ret[2],\n",
    "#     }\n",
    "# torch.save(checkpoint, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0d14ac5-cc0b-4c1e-8f51-92a55c83e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- test\n",
    "idx = 0\n",
    "data = trainset[idx]\n",
    "for k, v in data.items():\n",
    "    data[k] = v.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98a53e41-8ba6-42d4-ba40-f23d20951aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3690953/39771507.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(score)  # [L']\n"
     ]
    }
   ],
   "source": [
    "node_features = model.rnn(data[\"text_len_tensor\"], data[\"text_tensor\"]) # [batch_size, mx_len, D_g]\n",
    "features, edge_index, edge_norm, edge_type, edge_index_lengths = batch_graphify(\n",
    "    node_features, data[\"text_len_tensor\"], data[\"speaker_tensor\"], args.wp, args.wf,\n",
    "    model.edge_type_to_idx, model.edge_att, args.device)\n",
    "\n",
    "# graph_out = self.gcn(features, edge_index, edge_norm, edge_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe0bf54d-2268-49a8-bc56-502e8571c841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.nn import RelGraphConv\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "g_dim = 200\n",
    "h1_dim = 100\n",
    "h2_dim = 100\n",
    "hc_dim = 100\n",
    "tag_size = 6\n",
    "\n",
    "\n",
    "g = dgl.graph((edge_index[0], edge_index[1]))\n",
    "g.norm = edge_norm\n",
    "# g.etypes= edge_type\n",
    "conv = RelGraphConv(g_dim, h1_dim, h2_dim, regularizer='basis', num_bases=30).cuda()\n",
    "conv1 = GraphConv(h1_dim, h2_dim).cuda()\n",
    "# res = conv(g, feat, etype)\n",
    "\n",
    "res = conv(g, features, edge_type)\n",
    "res2 = conv1(g, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8aaf191d-107d-428f-8400-0a5450e13dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=1567, num_edges=29387,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d0f44-5399-45e6-8bd9-551aaf247b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3206d8-e170-4293-af62-24840916ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dim = 200\n",
    "        h1_dim = 100\n",
    "        h2_dim = 100\n",
    "        hc_dim = 100\n",
    "        tag_size = 6\n",
    "\n",
    "        self.wp = args.wp\n",
    "        self.wf = args.wf\n",
    "        self.device = args.device\n",
    "\n",
    "        self.rnn = SeqContext(u_dim, g_dim, args)\n",
    "        self.edge_att = EdgeAtt(g_dim, args)\n",
    "        self.gcn = GCN(g_dim, h1_dim, h2_dim, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5cb8d2-2cfe-4457-8ecc-02b17e79eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from dgl.nn import RelGraphConv\n",
    ">>>\n",
    "g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n",
    "feat = th.ones(6, 10)\n",
    "conv = RelGraphConv(10, 2, 3, regularizer='basis', num_bases=2)\n",
    "etype = th.tensor([0,1,2,0,1,2])\n",
    "res = conv(g, feat, etype)\n",
    "\n",
    "\n",
    "res\n",
    "tensor([[ 0.3996, -2.3303],\n",
    "        [-0.4323, -0.1440],\n",
    "        [ 0.3996, -2.3303],\n",
    "        [ 2.1046, -2.8654],\n",
    "        [-0.4323, -0.1440],\n",
    "        [-0.1309, -1.0000]], grad_fn=<AddBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd48b08-647b-422d-9543-ba533fb063ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "epoch_loss = 0\n",
    "self.model.train()\n",
    "for epoch in range(1, args.epochs)\n",
    "    for idx in range(len(trainset):\n",
    "        model.zero_grad()\n",
    "        data = trainset[idx]\n",
    "        for k, v in data.items():\n",
    "            data[k] = v.to(args.device)\n",
    "        nll = model.get_loss(data)\n",
    "        epoch_loss += nll.item()\n",
    "        nll.backward()\n",
    "        self.opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719cb03-14df-4b99-b78a-d29f0241e035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbb3df-49ac-4353-978a-8b209b52abf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad5b50-d6e6-4271-bb0c-e70dbb9a961c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5554723-1fea-463b-aed2-46f63c016b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67448923-6053-433c-9638-672c2dc8a02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd11cf6-f50f-43d8-a449-0b93246e1901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151b833-a19c-47b9-9a7f-cd432752d5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3eea1-2521-46e1-8ac3-f3208f6a31fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c4769-e22f-4d58-956b-ad2a822ca7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe956c-e4df-4a57-b1a6-a296d0619f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89d2c9-4d13-46a6-90c7-eca6ac56735c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a264e91-daf6-487a-89e4-fa4b34f74ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN_pytorch_DGL",
   "language": "python",
   "name": "gnn_pytorch_dgl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
